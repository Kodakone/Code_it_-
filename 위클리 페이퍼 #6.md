Weekly_Paper #6
=============

> # CNN을 구성하는 각 레이어의 역할에 대해 설명해보세요.

#### CNN은 이미지나 시계열 데이터에서 특징을 추출하고 학습하는 데 특화된 인공신경망을 의미. 이는 특징을 추출하는 Convolutional Layer와 정보를 압축하는 Pooling Layer의 반복으로 이루어져 있다.

1. Input Layer는 CNN의 첫 번째 레이어로, 입력 데이터(이미지, 시계열 데이터 등)를 받음.
예를 들어, 28×28 크기의 흑백 이미지를 입력하면 (28, 28, 1), 
컬러 이미지는 (28, 28, 3) 형태로 들어가게 된다.

2. Convolution Layer는 입력 데이터에서 특징(feature)을 추출하는 역할을 한다. 
작은 행렬의 필터를 이용하여 이미지를 스캔하면서, 해당 Data에 대한 경계선, 텍스처 등의 특징을 학습.

Layer 초기에는 경계선이나, 직선, 대각선 등 단순 패턴을 감지하며, 
이후 중간 Layer는 텍스처, 곡선, 윤곽선 등 조금 더 복잡한 패턴을 학습, 
더 깊은 후반의 Layer는 객체의 이루어진 형태(완성된 얼굴, 손 등)를 학습하게 된다.

3. Pooling Layer는 특징 맵의 크기를 줄여 연산량을 감소시키고, 중요한 특징을 유지하면서 불필요한 정보를 제거한다.
이때, pooling 방법에는 특정 영역에서 가장 큰 값을 추출하는 max pooling, 
영역 내 값들을 평균내어 추출하면 average pooling이 있다.

4. Fully Connected Layer는 Convolution Layer와 Pooling Layer를 거쳐 추출된 Feature를 1차원으로 만들어서, 이를 기반으로 최종 예측을 수행한다. 예를 들어, 입력 이미지를 특정 클래스(예: 개, 고양이 등)로 분류하는 역할을 하는 것이다. 이는 일반적으로 요소들 간의 완전히 연결된 다층 퍼셉트론(MLP) 구조를 지님.

5. Output Layer는 최종적으로 각 클래스에 대한 확률을 출력한다. SoftMax 등의 활성 함수를 이용하여, 만약 얼룩말 Image를 입력으로 사용하면 Horse 클래스일 확률은 0.2, Zebra 클래스일 확률은 0.7, Dog 클래스일 확률은 0.1이라는 것을 도출하게 된다.

---------------------------------

> # 오토 인코더가 적용되기 적합한 상황에 대해 설명하고, 오토 인코더를 구성하는 인코더(Encoder)와 디코더(Decoder) 각각의 개념과 차이점에 대해 설명하세요.

#### 오토인코더(Autoencoder)는 입력 데이터가 들어왔을 때, 해당 데이터를 최대한 압축시킨 후, 데이터의 특징을 추출하여 다시 본래의 입력 형태로 복원시키는 신경망. 

이때, 데이터를 압축하는 부분을 Encoder, 복원하는 부분을 Decoder라고 한다.

### 인코더(Encoder)는 입력 데이터를 압축하는 역할
이는 입력 데이터의 중요한 특징만 추출하고, 불필요한 정보를 제거한다. 예를 들어, 고차원 데이터에서 주요 패턴만 학습하는 역할을 한다.

### 디코더(Decoder)는 잠재 공간에서 압축된 표현을 다시 원래 데이터로 복원하는 역할
을 한다. 디코더는 인코더가 학습한 특징을 기반으로 데이터의 세부 정보를 복원하며, 입력 데이터와 유사한 출력을 생성한다.

### AutoEncoder가 적합한 상황: 차원 축소, 노이즈 제거, 이상치 탐지

1) 차원 축소\
오토인코더는 입력 데이터를 압축한 뒤, 다시 원래 크기로 복원하도록 학습하는 신경망이다. 이 과정에서 데이터의 핵심적인 특징만을 남기고 불필요한 정보를 제거하기 때문에 차원 축소에 사용된다.

2) 노이즈 제거\
Denoising Autoencoder(DAE)는 일반 오토인코더와 동일한 구조이지만, 학습 시 일부러 노이즈가 포함된 데이터를 입력하고, 깨끗한 원본 데이터를 복원하도록 학습한다. 노이즈는 랜덤한 요소로 존재하기 때문에, 오토인코더는 노이즈를 학습하지 않는다. 반면, 원본 데이터의 주요 특징은 반복적으로 나타나기 때문에 모델이 이를 학습하고 복원하는 능력이 향상된다. 즉, 모델은 입력 데이터의 노이즈를 제거한 후, 핵심적인 특징만 복원하는 걸 반복 학습하게 되는 것이다.

3) 이상치 탐지\
정상 데이터를 학습한 모델은 이상 데이터를 복원하기 어려워 한다. 이상치는 자연스럽게 학습에서 누락되지 때문에, 이를 기반으로 이상치를 탐지할 수 있다.

