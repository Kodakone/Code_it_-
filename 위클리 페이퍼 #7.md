Weekly_Paper #7
=============

> # 이미지를 모델에 입력하기 전에 리사이징(Resizing)과 정규화(Normalization)를 하는 이유는 무엇인가요?

#### 딥러닝 모델에 이미지를 입력하기 전에 리사이징(Resizing)과 정규화(Normalization)는 전처리 과정이라 하며, 이를 거치는 이유는 모델 학습의 효율성과 성능을 높이기 위해서.

리사이징(Resizing)은 모든 입력 이미지의 특정 크기로 통일하기 위해 필요한 과정. 
딥러닝 모델은 고정된 크기의 입력을 받도록 설계되므로, 다양한 크기의 이미지를 일관된 형태로 맞춰야 한다. 
예를 들어, VGG / ResNet과 같은 사전 학습된 모델은 일반적으로 224x224 크기의 이미지를 입력으로 받는다. 따라서, 모델이 학습할 수 있도록 모든 이미지를 동일한 크기로 변환해야 한다

정규화(Normalization)는 이미지의 픽셀 값 범위를 일정 범위로 조정하는 과정이다. 
일반적으로 이미지의 픽셀 값은 0에서 255 사이의 정수값을 가지는데, 이를 [0, 1] 범위 또는 평균을 0, 표준편차를 1로 조정하는 방식으로 정규화하여, Scale이 큰 feature의 영향이 비대해지는 것 방지해 모델이 안정적이게 되며 / 딥러닝에서 Local Minima에 빠질 위험을 감소시킨다(경사 소실(vanishing gradient) 문제 완화). 

일반적으로 MinMaxScaler 방식 사용.
<img width="800" height="199" alt="image" src="https://github.com/user-attachments/assets/384d44af-e69f-4c9d-9cc0-20879b355acf" />


또한, 정규화를 통해 데이터의 분포를 일정하게 맞춰주면 모델이 특정 값 범위에 편향되지 않고 더 효과적으로 특징을 학습할 수 있다. 결론적으로, 리사이징은 입력 형태를 맞춰주고, 정규화는 학습을 안정적으로 진행하도록 도와주는 과정이다.

---------------------------------

> # 데이터 증강(Data Augmentation)이란 무엇이며, 이미지 데이터에서 주로 사용하는 증강 기법에는 어떤 것들이 있나요?

#### 데이터 증강(Data Augmentation)이란 기존 데이터에 다양한 변형을 가하여 새로운 학습 데이터를 생성하는 기법.
딥러닝 모델은 많은 데이터를 필요로 하지만, 충분한 양의 데이터를 확보하기 어려운 경우가 많다. 
이때, 데이터 증강을 활용하면 기존 데이터를 다양하게 변형하여 모델의 일반화 성능을 향상시킬 수 있다. 
이를 통해 과적합(overfitting)을 방지하고, 모델이 특정 패턴에 치우치지 않도록 학습할 수 있다.

이미지 데이터에서 자주 사용하는 데이터 증강 기법에는 다음과 같은 것들이 있습니다.

1) 회전(Rotation): 이미지를 특정 각도로 회전시켜 모델이 다양한 방향에서의 데이터를 학습할 수 있다.
2) 수평/수직 뒤집기(Flipping): 특히 수평 뒤집기는 이미지 데이터가 좌우 대칭성을 가질 때 효과적인 방법.
3) 잘라내기(Cropping): 이미지의 일부분을 랜덤하게 잘라내어 다양한 시각적 변화 학습.
4) 크기 변환(Scaling): 이미지를 확대 및 축소하여 다양한 시각적 변화를 학습.
5) 밝기 및 색상 변화(Brightness & Color Jittering): 이미지의 밝기, 대비, 색조 등을 조정하여 다양한 조명 환경에서도 모델이 잘 작동하도록 함.
6) 노이즈 추가(Adding Noise): 이미지에 랜덤한 노이즈를 추가하여, 모델이 깨끗한 데이터뿐만 아니라 노이즈가 포함된 데이터도 잘 인식할 수 있도록 학습. (단, 과한 Noise 말고. 오히려 학습 방해 될 수도)

이러한 데이터 증강 기법들은 이미지 데이터의 다양성을 증가시키고, 모델이 보다 일반적인 특징을 학습하도록 돕는 중요한 역할을 하게 된다.

---------------------------------

> # Transfer Learning(전이 학습)이란 무엇이며, 이미지 분류 모델에서 어떻게 활용할 수 있나요?

#### 전이 학습(Transfer Learning)이란 이미 학습된 모델의 가중치를 활용하여 새로운 데이터나 문제에 적용하는 기법. 
딥러닝 모델을 처음부터 학습하려면 많은 데이터와 연산 자원(특히, 시간 및 GPU 요소)이 필요하지만, 전이 학습을 사용하면 기존에 학습된 지식을 재사용하여 적은 데이터로도 좋은 성능을 얻을 수 있습니다.

이미지 분류 모델에서 전이 학습을 활용하는 방법은 크게 두 가지가 있다.

1) 특징 추출(Feature Extraction)
사전 학습된 모델의 합성곱 층(Convolutional Layers)은 일반적인 이미지 특징(엣지, 패턴, 질감 등)을 잘 학습하고 있기 때문에, 이 부분을 그대로 사용하고 마지막 분류 층(Fully Connected Layer)만 새롭게 학습하는 방법이다.
예를 들면, ResNet이나 VGG 같은 사전 학습된 모델을 로드한 후, 마지막 출력 층만 교체하고 새로운 데이터셋에 맞춰 학습시키는 방식이 이에 해당.

2) 미세 조정(Fine-Tuning)
이 방법은 사전 학습된 모델을 일부 수정하여 새로운 데이터에 맞춰 추가 학습하는 방식. 
특정 층(예: 상위 몇 개 층)은 고정하고, 나머지 층들은 새로운 데이터에 맞춰 학습할 수 있도록 설정하여 모델이 기존의 일반적인 특징뿐만 아니라 새로운 데이터셋의 특징도 학습할 수 있도록 한다.

전이 학습은 소규모 데이터셋을 활용한 모델 학습이나, 객체 탐지(Object Detection) 등의 다양한 이미지 분석 분야에서 많이 사용된다. 이는 대규모 데이터셋(예: ImageNet)에서 학습된 모델을 활용함으로써, 학습 시간을 단축하고 일반화 성능을 높이는 데 큰 장점이 있다.


