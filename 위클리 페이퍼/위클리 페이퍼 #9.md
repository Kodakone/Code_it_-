Weekly_Paper #9
=============

> # Semantic Segmentation이란 무엇이며, 이미지 분류(Classification)와 어떤 차이가 있나요?

#### 
Semantic Segmentation이란 이미지 내 각 픽셀에 대해 특정 클래스를 할당하는 작업을 의미합니다. 즉, 이미지 속의 모든 픽셀이 어떤 객체나 배경에 속하는지를 분류하는 것입니다.

Semantic Segmentation과 이미지 분류(Classification)의 가장 큰 차이점은 출력 형태입니다. 이미지 분류는 입력 이미지 전체에 대해 단 하나의 클래스를 예측하는 반면, 
Semantic Segmentation은 픽셀 단위로 분류를 수행합니다. 예를 들어, 개와 고양이가 함께 있는 사진을 이미지 분류 모델에 입력하면 "개" 또는 "고양이" 중 하나로 분류될 수 있습니다. 
하지만 Semantic Segmentation 모델은 이미지의 모든 픽셀을 분석하여 개의 영역과 고양이의 영역을 각각 분리하여 표시할 수 있습니다.

Semantic Segmentation은 자율주행(차선 및 보행자 감지), 의료 영상 분석(암 조직 탐지), 위성 영상 처리(토지 유형 분류) 등 다양한 분야에서 활용됩니다. 
픽셀 단위로 정확한 영역을 식별할 수 있어, 물체의 경계를 정확히 구별해야 하는 작업에서 특히 중요한 역할을 합니다.

---------------------------------

> # Fully Convolutional Networks(FCN)의 주요 특징과 기존 CNN 기반 분류 모델과의 차이점은 무엇인가요?

#### 
Fully Convolutional Networks(FCN)는 기존의 CNN을 확장하여 픽셀 단위의 예측을 수행하는 신경망 모델입니다.
일반적인 CNN 기반 분류 모델은 입력 이미지에서 특징을 추출한 후, 완전 연결층(Fully Connected Layer)을 거쳐 최종적으로 하나의 클래스를 출력합니다. 
그러나 FCN은 완전 연결층을 제거하고, 대신 컨볼루션 연산만을 사용하여 전체 이미지의 공간적 정보를 유지하면서 픽셀 단위로 클래스를 예측할 수 있도록 설계되었습니다.

FCN의 가장 큰 특징은 업샘플링(Upsampling) 또는 디컨볼루션(Deconvolution) 연산을 사용하여 입력 이미지와 동일한 크기의 출력을 생성할 수 있다는 점입니다. 
이를 통해, 이미지 내 각 픽셀에 대해 클래스 라벨을 할당하는 Semantic Segmentation 작업이 가능해집니다.

기존의 CNN 기반 분류 모델과 비교했을 때, FCN의 주요 차이점은 다음과 같습니다.

첫째, 출력 형태의 차이입니다. 일반적인 CNN 모델은 전체 이미지에 대한 하나의 클래스 예측값을 반환하는 반면, FCN은 입력 이미지와 동일한 크기의 픽셀 단위 예측 결과를 출력합니다.
둘째, 완전 연결층(Fully Connected Layer)의 제거입니다. FCN은 전통적인 CNN에서 마지막에 사용되는 완전 연결층을 제거하고, 모든 레이어를 컨볼루션 연산으로 대체하여 입력 이미지의 공간적 정보를 유지합니다.
셋째, 업샘플링을 활용한 복원 과정입니다. CNN의 다운샘플링(Stride, Pooling) 과정에서 손실된 해상도를 복구하기 위해 FCN은 업샘플링 기법을 활용하여 원본 크기의 예측 맵을 생성합니다. 이를 통해 모델이 픽셀 단위로 세밀한 예측을 수행할 수 있도록 합니다.

---------------------------------
  
> # GAN에서 생성자(Generator)와 판별자(Discriminator)의 역할은 각각 무엇인가요?

####
GAN(Generative Adversarial Networks)은 두 개의 신경망인 생성자(Generator)와 판별자(Discriminator)가 서로 경쟁하면서 데이터를 생성하는 모델입니다.

생성자(Generator)는 새로운 데이터를 만들어내는 역할을 합니다. 랜덤한 노이즈를 입력으로 받아, 실제 데이터와 구별할 수 없을 정도로 유사한 데이터를 생성하는 것이 목표입니다.
생성자는 학습을 거듭하면서 점점 더 현실적인 데이터를 만들어내도록 발전합니다.

반면, 판별자(Discriminator)는 입력된 데이터가 실제 데이터인지, 생성자가 만든 가짜 데이터인지 구별하는 역할을 합니다.
처음에는 가짜 데이터를 쉽게 구별할 수 있지만, 생성자가 점점 더 정교한 데이터를 만들면서 판별자의 판단이 어려워지게 됩니다.

이 두 네트워크는 적대적 학습(adversarial learning)을 통해 서로 경쟁하며 성능을 향상시킵니다. 
생성자는 판별자를 속이기 위해 점점 더 현실적인 데이터를 만들어내려 하고, 판별자는 생성자가 만든 데이터를 더 정확하게 구별하려고 학습합니다. 
결국, 이 과정이 반복되면서 생성자는 점점 더 실제 데이터와 구별하기 어려운 고품질의 데이터를 생성할 수 있게 됩니다.

---------------------------------

> # Diffusion 모델이 이미지 생성에서 어떻게 활용되며, 어떤 장점이 있나요?

####
Diffusion 모델은 이미지 생성에서 확률적 과정(노이즈 추가 및 제거)을 활용하여 고품질의 이미지를 생성하는 기법입니다.
이 모델은 초기에는 랜덤한 노이즈를 포함한 이미지에서 점진적으로 원래의 데이터 분포를 복원하는 방식으로 동작합니다.

Diffusion 모델의 기본 아이디어는 데이터에 점진적으로 노이즈를 추가하는 전방향 과정(Forward Process)과, 이 노이즈를 단계적으로 제거하여 원본 데이터를 복원하는 역방향 과정(Reverse Process)으로 구성됩니다. 
훈련 과정에서 모델은 노이즈가 추가된 데이터를 보고, 이를 원래 데이터로 복원하는 방법을 학습합니다. 따라서, 학습이 완료되면 순수한 노이즈에서 점진적으로 의미 있는 패턴을 복원하며 새로운 이미지를 생성할 수 있습니다.

Diffusion 모델은 이미지 생성 분야에서 다음과 같은 장점을 가집니다.

첫째, 고품질 이미지 생성이 가능합니다. 기존 생성 모델(GAN, VAE)과 비교했을 때, Diffusion 모델은 더욱 세밀하고 자연스러운 이미지를 생성할 수 있으며, 특정 구조적 결함(예: GAN의 모드 붕괴 문제)이 적습니다.
둘째, 안정적인 학습 과정을 제공합니다. GAN은 생성자와 판별자 간의 경쟁으로 인해 학습이 불안정해질 수 있지만, Diffusion 모델은 확률적 모델링을 기반으로 하기 때문에 학습이 비교적 안정적입니다.
셋째, 다양한 데이터 생성이 가능합니다. Diffusion 모델은 다양한 데이터 분포를 학습할 수 있어, 단순한 이미지 생성뿐만 아니라 스타일 변환, 텍스트-이미지 생성, 의료 영상 복원 등의 응용에도 활용됩니다.
