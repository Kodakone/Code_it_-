Weekly_Paper #2
=============

> # 지도 학습과 비지도 학습의 차이는 무엇인가요?
Dataset(입력값)에 Label(정답, 출력값)을 지정하여 학습을 진행 하느냐 마느냐의 차이.

## 지도 학습: Label(정답, 출력값)이 지정되어 있는 Dataset을 입력 값으로 사용하는 ML 학습 방법
이는 Dataset과 Label의 상관 관계를 학습하여, 미래의 유사한 Dataset을 들여와도 정답을 예측할 수 있도록 하는 방식이다.

지도 학습은 주로 2가지 유형이 존재.
#### 회귀: Dataset과 Label간의 관계를 나타내는 방법
    ex) 선형 회귀, 로지스틱 회귀, 다항식 회귀 등

<img width="204" height="192" alt="image" src="https://github.com/user-attachments/assets/586c4a5a-a53c-475c-90c1-875d0ce2805a" />
    
#### 분류: Dataset을 특정 Class(Label)로 할당하는 방법
    ex) 선형 분류기, SVM, 결정 트리 등

<img width="266" height="190" alt="image" src="https://github.com/user-attachments/assets/64981738-e51a-4361-a31e-91a57f984b15" />


## 비지도 학습: Label(정답, 출력값)이 지정되어 있지 않은 Dataset을 입력하여 분석하는 ML 학습 방법
이는 정해진 정답이 없어 사람의 개입이 없이, 컴퓨터의 판단 하 Dataset 내부의 숨겨진 구조나 특징을 찾고 학습하는 방식이다.

비지도 학습은 주로 3가지 유형이 존재.
#### 클러스터링: Label이 없는 Dataset을 유사/차이에 따라 그룹화
  ex) K-means 클러스터링 등

<img width="256" height="197" alt="image" src="https://github.com/user-attachments/assets/b06aa554-fc1e-4b99-8b93-e3c4cf98abd0" />

#### 연관: Dataset에서 변수간의 관계를 찾음
  ex) 장바구니 분석, 추천 엔진 등

<img width="245" height="206" alt="image" src="https://github.com/user-attachments/assets/da5d9600-f40d-48fd-9b7f-32a06c0c64d0" />

#### 차원 축소: 특정 Dataset의 feature, dimension이 많으면 입력 수를 관리 가능하게끔 줄임
  ex) Autoencoders 등

<img width="412" height="122" alt="image" src="https://github.com/user-attachments/assets/c802a35e-81fe-4087-ac4d-85fb8341fa58" />


------------------------------------------
> # 손실 함수(loss function)란 무엇이며, 왜 중요한가요?

## 손실함수는 머신러닝이나 딥러닝 모델이 예측 값과 실제 값 사이의 차이를 측정하는 함수.
손실 함수가 중요한 이유는, 모델의 성능을 평가하고 어떤 방향으로 개선되어야 할지 알려주는 주요한 역할을 하기 때문. ML/DL에서는 손실함수의 결과 값을 최소화하여 모델의 성능을 끌어올리는 것이 궁극적인 목표이다. - 모델의 파라미터(w,b) 최적화 및 평가 가능 -

손실 함수의 종류는 다음 종류가 있다. 
#### Mean Squared Error (MSE)
    실제 값과 예측된 값의 차이를 제곱한 값들의 평균

<img width="397" height="127" alt="image" src="https://github.com/user-attachments/assets/4ca99a0d-7380-4afb-ae79-d8ac7fe21fa7" />
  
#### Root Mean Squared Error (RMSE)
    MSE에 제곱근. 오차를 실제 값과 동일 차원 표현

<img width="402" height="125" alt="image" src="https://github.com/user-attachments/assets/d2c438ca-a3e2-48f8-a0eb-1282abbffe33" />

#### Binary Cross-Entropy (이진 엔트로피)
    이진 분류에서 예측 확률과 실제 클래스 사이의 차이

<img width="600" height="52" alt="image" src="https://github.com/user-attachments/assets/4a4fd53d-87af-4aea-8a44-3e8dc7757768" />


#### Cross-Entropy Loss (교차 엔트로피)
    다중 클래스 분류에서 각 클래스 예측 확률과 실제 클래스 사이의 차이 측정

<img width="447" height="113" alt="image" src="https://github.com/user-attachments/assets/301fee88-37a1-4d80-8219-aeacba7b7595" />

    
#### Focal Loss
    Cross Entropy의 클래스 불균형 개선. 어렵거나 쉽게 오분류되는 Case에 더 큰 가중치.

<img width="1776" height="1843" alt="image" src="https://github.com/user-attachments/assets/f426b4aa-c098-49ee-a3b5-7b04a7a93d15" />


-------------------------------------------------------------
> # 모델 학습 시 발생할 수 있는 편향과 분산에 대해 설명하고, 두 개념의 관계에 대해 설명해 주세요.

## 편향: 예측값들과 실제값들이 대체로 멀리 떨어져 있는가?
## 분산: 예측값들이 본인들 끼리 멀리 흩어져 있는가?

ML/DL 에서는 학습을 여러 번 시행하여 여러 예측값을 내놓게 되는데, 이 예측값이 실제 값(정답)과 어떻게 다르게 드러나는가?의 지표로 사용되는 개념이 편향과 분산이다. 

#### 이해 쉽게, 사격 과녁을 예시. 
목표에 대한 점군이 잘 모여있으나, 목표점과 거리가 멀리 떨어져 있음 = 편향되어있다! \
목표에 대한 위치는 적절하나, 점군이 넓게 퍼져있다 = 분산되어있다!

주로 편향과 분산은 ML/DL 모델이 복잡하게 생긴 정도(차원의 높고 낮음)에 따라 관련이 크게 나타남. 

<img width="602" height="543" alt="image" src="https://github.com/user-attachments/assets/543f49ea-dbf4-4462-bc55-85350bf7f7a9" />

#### Underfitting = (high bias, low variance)
#### Good fitting = (medium bias, medium variance)
#### Overfitting = (low bias, high variance)

------------------------------------------

> # K-폴드 교차 검증에서 K의 값을 선택할 때 고려해야 할 점은 무엇인가요?
고정된 Train/Test data로 평가시, Train data에만 최적 성능이 나타나는 경향(과적합).
=> 이를 피하기 위해, 각 부분을 반복하여 Train/Vaildation 해 모델의 성늠을 좀 더 정확하게 평가하는 교차 검증 시행. (Test-Valid 내부적으로 K번 반복하는게 K-폴드 교차검증) 

<img width="1020" height="626" alt="image" src="https://github.com/user-attachments/assets/468f467e-c053-4d11-827b-f0e9cc7081b2" />


## K값은 Dataset의 크기, 계산 비용(시간), 신뢰성등 고려해 적절히 선택해야!
+ Dataset 크기가 크면, K값도 커야 함. (그 반대도 마찬가지)
+ K값이 커지면, 모델이 K번 Train - Valid 하므로 비용 커짐. 적절한 K값 필요
+ K값 크면, Valid data 크기 작아짐 = 평가 세밀, 신뢰성 높아짐. 그러나, Valid data 너무 작으면 결과 불안정. (반대시, Vaild data가 커 많은 평가가 가능하나, 분산이 커져 신뢰성 낮을수도)

Default: K = 5. 많으면 K = 10





