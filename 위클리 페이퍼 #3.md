Weekly_Paper #3
=============

> # 결정 트리(Decision Tree)의 장점과 단점은 무엇인가요?

### 결정 트리(Decision Tree): 나무의 구조를 기반으로 예/아니오의 의사결정 규칙을 만들고, 데이터를 분석하는 모델
결정 트리는 분류/회귀 전부 가능한 지도 학습 모델로, 데이터를 계층적으로 표현이 가능하다. 
간단히 말하자면, 예/아니오를 일종의 스무 고개 하듯 분기로 나누어 결과를 도출해낼 수 있다. 

<img width="382" height="267" alt="image" src="https://github.com/user-attachments/assets/eac984ff-729e-4b15-9ca6-6389f21d4e2e" />

동물을 구분하기 위해 결정 트리를 사용한 예시

<img width="409" height="291" alt="image" src="https://github.com/user-attachments/assets/567cc0ee-cd47-49bd-ad32-e5e67b09a155" />

결정 트리 구조

각 용어에 대해 간단히 설명하자면, 
+ 결정 트리의 시작점 = 뿌리(Root node)
+ 결정 트리 분기점 = 노드(Node)
+ node로부터 연결 된 하위 node = 자식 노드(Child node)
+ node로부터 연결 된 상위 node = 부모 노드(Parent node)
+ 자식 노드 없는, 맨 끝 node = 단말 노드(Leaf node)
+ 노드 연결 선 = 가지(Edge)
+ 뿌리 ~ 각 노드 간 깊이 = 레벨(Level)
+ 각 노드의 자식 노드 수 = 차수(degree)
+ 가장 긴 루트 경로의 길이 = 높이(height) 

## 장점
**시각적으로 이해하기 쉽고 직관적** \
**범주와 연속 수치 모두 예측 가능**\
**데이터 전처리 요구가 비교적 적음**\
**불규칙적인 자료(ex, 사회·경제적 맥락 자료 등)에 유용한 분석이 가능**

## 단점
**overfitting에 취약**\
**noise가 포함되면 정확한 예측 어렵**\
**분류 기준 값 근방의 자료는 오차가 클 수 있음**

------------------------------------------
> # 부스팅은 어떤 특징을 가진 앙상블 기법인가요? 토픽에서 배운 AdaBoost 이외의 부스팅 모델에는 무엇이 있는지에 대해 구글 등을 활용하여 직접 리서치해보고, 각 부스팅 모델의 특징, 장단점에 대해 말해주세요.

## 부스팅(Boosting): 성능이 약한 모델들을 중심으로 가중치를 활용해 모델의 성능을 극대화 시키는 기법
부스팅은 약한 성능의 모델들을 여럿 사용하여, 먼저 훈련을 진행한 모델이 다음 훈련을 진행 할 모델에 대해 Dataset을 바꿔서 학습하도록 한다. 
이때, 바뀐 Dataset은 잘못 분류된 데이터에 가중치를 주어 다음 모델이 원활히 학습할 수 있도록 한다. 
이러한 과정들을 거친 뒤, 최종 결과에서의 높은 예측 성능을 보임.  

## 부스팅 모델 종류 (AdaBoost 제외)

+ #### GBM(Gradient Boosting Model)
  - 이 모델은 AdaBoost처럼 학습마다 오답에 가중치를 부여하는 대신, GBM은 이전 모델에서 만든 잔차(residual)를 기반으로 학습을 진행함.
    이 잔차를 최소화 하기 위해, 경사 하강법(Gradient Descent)를 이용해 손실함수의 기울기를 최소화 하는 방향으로 학습 진행.
  - 장점: 수치형, 범주형 모두 예측이 가능하며, 결측 처리 / Feature 중요도 선택이 쉬움.
  - 단점: 과적합(overfitting) 문제, 학습 속도가 느림
    
  + #### XGBoost
    - XGBoost는 기존 GBM 모델의 잔차를 줄일 경우, 과적합된다는 문제가 있어 GBM에 정규화 식을 추가한 모델.
      기존 GBM 모델에 확장된 버전으로 구조화된 데이터를 학습하는데 좋은 성능을 보임
    - 장점: 효율적인 병렬 처리 기능 및 자체 교차 검증, 평가 값 최적화 시 조기 종료가 가능
    - 단점: GBM보단 낫지만, 여전히 학습 속도 느림
  + #### LightGBM
    - LightGBM은 XGBoost와 유사하나, 속도와 메모리 효율성에서 개선된 모델로, 대규모 데이터 및 많은 Feature를 다룰 경우 뛰어난 성능을 보인다.
      Leaf-wise 성장 전략을 사용해 가장 큰 손실을 먼저 감소 시키는 방향으로 확장해 높은 예측 성능을 제공함.
    - 장점: 빠른 학습속도 및 메모리 사용량 감소
    - 단점: 1만개 이하의 작은 Dataset을 학습 할 경우, 과적합(overfitting) 문제
  + #### CatBoost
    - CatBoost는 약자(Categorical Boosting)대로 범주형 변수를 처리하는데 중점을 둔 모델.
      Ordinal Encoding(순서형 인코딩) 및 Target Encoding(범주의 평균 기반 인코딩)을 사용하여 범주형 및 대규모 데이터셋에 적합함.
    - 장점: 자동 전처리 및 최적의 파라미터 선택 기능, 타 GBM 대비 Overfitting 적음 
    - 단점: 결측 데이터 처리 X (XGBoost, LightGBM은 처리 함)

-------------------------------------------------------------
> # 차원 축소 기법인 주성분 분석과 요인 분석의 차이는 무엇인지 설명해 주세요.

## 주 성분 분석과 요인 분석의 가장 큰 차이는 ~ 이다. 
주 성분 분석은 ~
요인 분석은~

